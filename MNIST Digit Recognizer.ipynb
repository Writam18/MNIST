{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWvyngICi7ir",
        "colab_type": "text"
      },
      "source": [
        "#Method 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_dVEDJJILgq",
        "colab_type": "code",
        "outputId": "c113d415-5744-4304-e8d7-048c4694d8e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnMxXLJqIjoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "n_classes = 10 # MNIST total classes (0-9 digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mZrmL3qIuG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "y = tf.placeholder(tf.float32, [None, n_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE5qT9ZnIy8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(x, W):\n",
        "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "def maxpool2d(x):\n",
        "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPhGeCc4MmmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_neural_network(x):#, keep_rate):\n",
        "    weights = {\n",
        "        # 5 x 5 convolution, 1 input image, 32 outputs\n",
        "        'W_conv1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
        "        # 5x5 conv, 32 inputs, 64 outputs \n",
        "        'W_conv2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
        "        # fully connected, 7*7*64 inputs, 1024 outputs\n",
        "        'W_fc': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
        "        # 1024 inputs, 10 outputs (class prediction)\n",
        "        'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
        "    }\n",
        "\n",
        "    biases = {\n",
        "        'b_conv1': tf.Variable(tf.random_normal([32])),\n",
        "        'b_conv2': tf.Variable(tf.random_normal([64])),\n",
        "        'b_fc': tf.Variable(tf.random_normal([1024])),\n",
        "        'out': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "    # Reshape input to a 4D tensor \n",
        "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "    # Convolution Layer, using our function\n",
        "    conv1 = tf.nn.relu(conv2d(x, weights['W_conv1']) + biases['b_conv1'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv1 = maxpool2d(conv1)\n",
        "    # Convolution Layer\n",
        "    conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv2 = maxpool2d(conv2)\n",
        "     # Fully connected layer\n",
        "    # Reshape conv2 output to fit fully connected layer\n",
        "    fc = tf.reshape(conv2, [-1, 7*7*64])\n",
        "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc']) + biases['b_fc'])\n",
        "    output = tf.matmul(fc, weights['out']) + biases['out']\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDXxi0CGM7Qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_neural_network(x):\n",
        "    prediction = convolutional_neural_network(x)\n",
        "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )\n",
        "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "    \n",
        "    hm_epochs = 10\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        for epoch in range(hm_epochs):\n",
        "            epoch_loss = 0\n",
        "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
        "                epoch_loss += c\n",
        "\n",
        "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
        "\n",
        "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
        "\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "        print('Accuracy:',accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBF1VS2SOFCn",
        "colab_type": "code",
        "outputId": "fd7ea019-a413-437d-faa7-cb3d9e18d47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "train_neural_network(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 completed out of 10 loss: 959446.9084968567\n",
            "Epoch 1 completed out of 10 loss: 202641.69932937622\n",
            "Epoch 2 completed out of 10 loss: 121777.24138259888\n",
            "Epoch 3 completed out of 10 loss: 83071.93723592442\n",
            "Epoch 4 completed out of 10 loss: 56830.20201873779\n",
            "Epoch 5 completed out of 10 loss: 42930.29021835327\n",
            "Epoch 6 completed out of 10 loss: 30774.018712235906\n",
            "Epoch 7 completed out of 10 loss: 23916.525373458862\n",
            "Epoch 8 completed out of 10 loss: 20920.562118929694\n",
            "Epoch 9 completed out of 10 loss: 16029.618285179138\n",
            "Accuracy: 0.973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4_cWaGqj3I7",
        "colab_type": "text"
      },
      "source": [
        "#Method 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYvJ_7cWOLZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zsmjtBYk82J",
        "colab_type": "code",
        "outputId": "113d5458-4695-4982-e837-6e9f13394bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-37adf088ce13>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRtrRSbUlEz4",
        "colab_type": "code",
        "outputId": "b544766c-d000-442e-bd71-9da19832c0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"Size of:\")\n",
        "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
        "print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
        "print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of:\n",
            "- Training-set:\t\t55000\n",
            "- Test-set:\t\t10000\n",
            "- Validation-set:\t5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amlRfRYLlzLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Placeholder variable for the input images\n",
        "x = tf.placeholder(tf.float32, shape=[None, 28*28], name='X')\n",
        "# Reshape it into [num_images, img_height, img_width, num_channels]\n",
        "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
        "\n",
        "# Placeholder variable for the true labels associated with the images\n",
        "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')\n",
        "y_true_cls = tf.argmax(y_true, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKKy0xfqnN7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_conv_layer(input, num_input_channels, filter_size, num_filters, name):\n",
        "    \n",
        "    with tf.variable_scope(name) as scope:\n",
        "        # Shape of the filter-weights for the convolution\n",
        "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
        "\n",
        "        # Create new weights (filters) with the given shape\n",
        "        weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
        "\n",
        "        # Create new biases, one for each filter\n",
        "        biases = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
        "\n",
        "        # TensorFlow operation for convolution\n",
        "        layer = tf.nn.conv2d(input=input, filter=weights, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "        # Add the biases to the results of the convolution.\n",
        "        layer += biases\n",
        "        \n",
        "        return layer, weights\n",
        "\n",
        "      \n",
        "def new_pool_layer(input, name):\n",
        "    \n",
        "    with tf.variable_scope(name) as scope:\n",
        "        # TensorFlow operation for convolution\n",
        "        layer = tf.nn.max_pool(value=input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "        return layer\n",
        "      \n",
        "def new_relu_layer(input, name):\n",
        "    \n",
        "    with tf.variable_scope(name) as scope:\n",
        "        # TensorFlow operation for convolution\n",
        "        layer = tf.nn.relu(input)\n",
        "        return layer\n",
        "      \n",
        "def new_fc_layer(input, num_inputs, num_outputs, name):\n",
        "    \n",
        "    with tf.variable_scope(name) as scope:\n",
        "\n",
        "        # Create new weights and biases.\n",
        "        weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
        "        biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
        "        \n",
        "        # Multiply the input and weights, and then add the bias-values.\n",
        "        layer = tf.matmul(input, weights) + biases\n",
        "        \n",
        "        return layer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92yXSfgQrQ6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolutional Layer 1\n",
        "layer_conv1, weights_conv1 = new_conv_layer(input=x_image, num_input_channels=1, filter_size=5, num_filters=6, name =\"conv1\")\n",
        "\n",
        "# Pooling Layer 1\n",
        "layer_pool1 = new_pool_layer(layer_conv1, name=\"pool1\")\n",
        "\n",
        "# RelU layer 1\n",
        "layer_relu1 = new_relu_layer(layer_pool1, name=\"relu1\")\n",
        "\n",
        "# Convolutional Layer 2\n",
        "layer_conv2, weights_conv2 = new_conv_layer(input=layer_relu1, num_input_channels=6, filter_size=5, num_filters=16, name= \"conv2\")\n",
        "\n",
        "# Pooling Layer 2\n",
        "layer_pool2 = new_pool_layer(layer_conv2, name=\"pool2\")\n",
        "\n",
        "# RelU layer 2\n",
        "layer_relu2 = new_relu_layer(layer_pool2, name=\"relu2\")\n",
        "\n",
        "# Flatten Layer\n",
        "num_features = layer_relu2.get_shape()[1:4].num_elements()\n",
        "layer_flat = tf.reshape(layer_relu2, [-1, num_features])\n",
        "\n",
        "# Fully-Connected Layer 1\n",
        "layer_fc1 = new_fc_layer(layer_flat, num_inputs=num_features, num_outputs=128, name=\"fc1\")\n",
        "\n",
        "# RelU layer 3\n",
        "layer_relu3 = new_relu_layer(layer_fc1, name=\"relu3\")\n",
        "\n",
        "# Fully-Connected Layer 2\n",
        "layer_fc2 = new_fc_layer(input=layer_relu3, num_inputs=128, num_outputs=10, name=\"fc2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFPXKV8rp6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Softmax function to normalize the output\n",
        "with tf.variable_scope(\"Softmax\"):\n",
        "    y_pred = tf.nn.softmax(layer_fc2)\n",
        "    y_pred_cls = tf.argmax(y_pred, dimension=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "majltNB-sclI",
        "colab_type": "code",
        "outputId": "cf90a963-f93d-438d-bdc2-8df51088a58c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Use Cross entropy cost function\n",
        "with tf.name_scope(\"cross_ent\"):\n",
        "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)\n",
        "    cost = tf.reduce_mean(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-cb0b5162bb09>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RCI0zVqsxq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Adam Optimizer\n",
        "with tf.name_scope(\"optimizer\"):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZQ9g7dbs7ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Accuracy\n",
        "with tf.name_scope(\"accuracy\"):\n",
        "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLWtNSfjtAvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the FileWriter\n",
        "writer = tf.summary.FileWriter(\"Training_FileWriter/\")\n",
        "writer1 = tf.summary.FileWriter(\"Validation_FileWriter/\")\n",
        "\n",
        "# Add the cost and accuracy to summary\n",
        "tf.summary.scalar('loss', cost)\n",
        "tf.summary.scalar('accuracy', accuracy)\n",
        "\n",
        "# Merge all summaries together\n",
        "merged_summary = tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8YLXeT4tT18",
        "colab_type": "code",
        "outputId": "37a1392f-53cf-45e0-848b-6689d8f50a8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "num_epochs = 10\n",
        "batch_size = 100\n",
        "with tf.Session() as sess:\n",
        "    # Initialize all variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    # Add the model graph to TensorBoard\n",
        "    writer.add_graph(sess.graph)\n",
        "    \n",
        "    # Loop over number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        start_time = time.time()\n",
        "        train_accuracy = 0\n",
        "        \n",
        "        for batch in range(0, int(len(data.train.labels)/batch_size)):\n",
        "            \n",
        "            # Get a batch of images and labels\n",
        "            x_batch, y_true_batch = data.train.next_batch(batch_size)\n",
        "            \n",
        "            # Put the batch into a dict with the proper names for placeholder variables\n",
        "            feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
        "            \n",
        "            # Run the optimizer using this batch of training data.\n",
        "            sess.run(optimizer, feed_dict=feed_dict_train)\n",
        "            \n",
        "            # Calculate the accuracy on the batch of training data\n",
        "            train_accuracy += sess.run(accuracy, feed_dict=feed_dict_train)\n",
        "            \n",
        "            # Generate summary with the current batch of data and write to file\n",
        "            summ = sess.run(merged_summary, feed_dict=feed_dict_train)\n",
        "            writer.add_summary(summ, epoch*int(len(data.train.labels)/batch_size) + batch)\n",
        "        \n",
        "          \n",
        "        train_accuracy /= int(len(data.train.labels)/batch_size)\n",
        "        \n",
        "        # Generate summary and validate the model on the entire validation set\n",
        "        summ, vali_accuracy = sess.run([merged_summary, accuracy], feed_dict={x:data.validation.images, y_true:data.validation.labels})\n",
        "        writer1.add_summary(summ, epoch)\n",
        "        \n",
        "\n",
        "        end_time = time.time()\n",
        "        \n",
        "        print(\"Epoch \"+str(epoch+1)+\" completed : Time usage \"+str(int(end_time-start_time))+\" seconds\")\n",
        "        print(\"\\tAccuracy:\")\n",
        "        print (\"\\t- Training Accuracy:\\t{}\".format(train_accuracy))\n",
        "        print (\"\\t- Validation Accuracy:\\t{}\".format(vali_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 completed : Time usage 101 seconds\n",
            "\tAccuracy:\n",
            "\t- Training Accuracy:\t0.7357454537871209\n",
            "\t- Validation Accuracy:\t0.8939999938011169\n",
            "Epoch 2 completed : Time usage 101 seconds\n",
            "\tAccuracy:\n",
            "\t- Training Accuracy:\t0.9063636380975897\n",
            "\t- Validation Accuracy:\t0.9259999990463257\n",
            "Epoch 3 completed : Time usage 101 seconds\n",
            "\tAccuracy:\n",
            "\t- Training Accuracy:\t0.9283818191831762\n",
            "\t- Validation Accuracy:\t0.9391999840736389\n",
            "Epoch 4 completed : Time usage 100 seconds\n",
            "\tAccuracy:\n",
            "\t- Training Accuracy:\t0.9402909100055694\n",
            "\t- Validation Accuracy:\t0.9531999826431274\n",
            "Epoch 5 completed : Time usage 101 seconds\n",
            "\tAccuracy:\n",
            "\t- Training Accuracy:\t0.9491636380282316\n",
            "\t- Validation Accuracy:\t0.9589999914169312\n",
            "Epoch 6 completed : Time usage 101 seconds\n",
            "\tAccuracy:\n",
            "\t- Training Accuracy:\t0.9561272765289653\n",
            "\t- Validation Accuracy:\t0.9624000191688538\n",
            "Epoch 7 completed : Time usage 100 seconds\n",
            "\tAccuracy:\n",
            "\t- Training Accuracy:\t0.9611454569209705\n",
            "\t- Validation Accuracy:\t0.9667999744415283\n",
            "Epoch 8 completed : Time usage 101 seconds\n",
            "\tAccuracy:\n",
            "\t- Training Accuracy:\t0.9660909165035595\n",
            "\t- Validation Accuracy:\t0.9710000157356262\n",
            "Epoch 9 completed : Time usage 102 seconds\n",
            "\tAccuracy:\n",
            "\t- Training Accuracy:\t0.9695272796804255\n",
            "\t- Validation Accuracy:\t0.9728000164031982\n",
            "Epoch 10 completed : Time usage 101 seconds\n",
            "\tAccuracy:\n",
            "\t- Training Accuracy:\t0.971545463475314\n",
            "\t- Validation Accuracy:\t0.9760000109672546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KOp8rp5x7Do",
        "colab_type": "text"
      },
      "source": [
        "#Method 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7monBlZtzoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "%matplotlib inline\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIpSCSqk6mjc",
        "colab_type": "code",
        "outputId": "87a139fe-25bf-4be1-a0bb-096740344fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "data = input_data.read_data_sets('data/fashion',one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-c16302e8c919>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDWh0HSh6q_v",
        "colab_type": "code",
        "outputId": "8be527b6-ab1a-4cae-f827-11ec857848bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# Shapes of training set\n",
        "print(\"Training set (images) shape: {shape}\".format(shape=data.train.images.shape))\n",
        "print(\"Training set (labels) shape: {shape}\".format(shape=data.train.labels.shape))\n",
        "\n",
        "# Shapes of test set\n",
        "print(\"Test set (images) shape: {shape}\".format(shape=data.test.images.shape))\n",
        "print(\"Test set (labels) shape: {shape}\".format(shape=data.test.labels.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set (images) shape: (55000, 784)\n",
            "Training set (labels) shape: (55000, 10)\n",
            "Test set (images) shape: (10000, 784)\n",
            "Test set (labels) shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu7NRzxQ6xPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dictionary of target classes\n",
        "label_dict = {\n",
        " 0: 'T-shirt/top',\n",
        " 1: 'Trouser',\n",
        " 2: 'Pullover',\n",
        " 3: 'Dress',\n",
        " 4: 'Coat',\n",
        " 5: 'Sandal',\n",
        " 6: 'Shirt',\n",
        " 7: 'Sneaker',\n",
        " 8: 'Bag',\n",
        " 9: 'Ankle boot',\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tos4Z6Jo7JBT",
        "colab_type": "code",
        "outputId": "d07a176e-60ec-41bc-aac0-3da2e0db77c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "plt.figure(figsize=[5,5])\n",
        "\n",
        "# Display the first image in training data\n",
        "plt.subplot(121)\n",
        "curr_img = np.reshape(data.train.images[0], (28,28))\n",
        "curr_lbl = np.argmax(data.train.labels[0,:])\n",
        "plt.imshow(curr_img, cmap='gray')\n",
        "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
        "\n",
        "# Display the first image in testing data\n",
        "plt.subplot(122)\n",
        "curr_img = np.reshape(data.test.images[0], (28,28))\n",
        "curr_lbl = np.argmax(data.test.labels[0,:])\n",
        "plt.imshow(curr_img, cmap='gray')\n",
        "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '(Label: Sneaker)')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATcAAACtCAYAAADVqDijAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h+F5IdhdDZGKAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZKKKJXF7RkB",
        "colab_type": "code",
        "outputId": "4cbe81f0-1b16-4072-adcf-175cfb91c0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2744
        }
      },
      "source": [
        "data.train.images[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.3803922 , 0.37647063, 0.3019608 ,\n",
              "       0.46274513, 0.2392157 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.3529412 , 0.5411765 , 0.9215687 ,\n",
              "       0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,\n",
              "       0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 , 0.9607844 ,\n",
              "       0.9215687 , 0.74509805, 0.08235294, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.54901963,\n",
              "       0.9843138 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
              "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
              "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
              "       0.7411765 , 0.09019608, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.8862746 , 0.9960785 , 0.81568635,\n",
              "       0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,\n",
              "       0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,\n",
              "       0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,\n",
              "       0.08235294, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.14901961, 0.32156864, 0.0509804 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.13333334,\n",
              "       0.8352942 , 0.9960785 , 0.9960785 , 0.45098042, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.32941177, 0.9960785 ,\n",
              "       0.9960785 , 0.9176471 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.32941177, 0.9960785 , 0.9960785 , 0.9176471 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.4156863 , 0.6156863 ,\n",
              "       0.9960785 , 0.9960785 , 0.95294124, 0.20000002, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,\n",
              "       0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
              "       0.9960785 , 0.94117653, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.26666668, 0.4666667 , 0.86274517,\n",
              "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
              "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.5568628 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.14509805, 0.73333335,\n",
              "       0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 ,\n",
              "       0.8078432 , 0.8078432 , 0.29411766, 0.26666668, 0.8431373 ,\n",
              "       0.9960785 , 0.9960785 , 0.45882356, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 , 0.89019614,\n",
              "       0.45098042, 0.34901962, 0.12156864, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.7843138 , 0.9960785 , 0.9450981 ,\n",
              "       0.16078432, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.6627451 , 0.9960785 ,\n",
              "       0.6901961 , 0.24313727, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.18823531,\n",
              "       0.9058824 , 0.9960785 , 0.9176471 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.07058824, 0.48627454, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
              "       0.6509804 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.54509807, 0.9960785 , 0.9333334 , 0.22352943, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.8235295 , 0.9803922 , 0.9960785 ,\n",
              "       0.65882355, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.9490197 , 0.9960785 , 0.93725497, 0.22352943, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.34901962, 0.9843138 , 0.9450981 ,\n",
              "       0.3372549 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
              "       0.8078432 , 0.96470594, 0.6156863 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01568628, 0.45882356, 0.27058825,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvCY4x9p7feq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape training and testing image\n",
        "train_X = data.train.images.reshape(-1, 28, 28, 1)\n",
        "test_X = data.test.images.reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzOzCs6a7rIW",
        "colab_type": "code",
        "outputId": "5edd9ed9-2e42-46bd-f04f-d2fdb9629367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_X.shape, test_X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((55000, 28, 28, 1), (10000, 28, 28, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFrbwENL7uYp",
        "colab_type": "code",
        "outputId": "beb1148c-cfca-4c13-eccd-1892effa6de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_y = data.train.labels\n",
        "test_y = data.test.labels\n",
        "train_y.shape, test_y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((55000, 10), (10000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZAg3r7-703H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_iters = 200 \n",
        "learning_rate = 0.001 \n",
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fvA7YcA8Lh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST data input (img shape: 28*28)\n",
        "n_input = 28\n",
        "\n",
        "# MNIST total classes (0-9 digits)\n",
        "n_classes = 10\n",
        "\n",
        "#both placeholders are of type float\n",
        "x = tf.placeholder(\"float\", [None, 28,28,1])\n",
        "y = tf.placeholder(\"float\", [None, n_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqemyAZi8VCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(x, W, b, strides=1):\n",
        "    # Conv2D wrapper, with bias and relu activation\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "    x = tf.nn.bias_add(x, b)\n",
        "    return tf.nn.relu(x) \n",
        "\n",
        "def maxpool2d(x, k=2):\n",
        "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqstC_1j84ms",
        "colab_type": "code",
        "outputId": "3ac30ff3-9de2-46e9-df1d-0966d59a54d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "weights = {\n",
        "    'wc1': tf.get_variable('W0', shape=(3,3,1,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'wc2': tf.get_variable('W1', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'wc3': tf.get_variable('W2', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'wd1': tf.get_variable('W3', shape=(4*4*128,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'out': tf.get_variable('W6', shape=(128,n_classes), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "}\n",
        "biases = {\n",
        "    'bc1': tf.get_variable('B0', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bc2': tf.get_variable('B1', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bc3': tf.get_variable('B2', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bd1': tf.get_variable('B3', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'out': tf.get_variable('B4', shape=(10), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNBchlNf9Bss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_net(x, weights, biases):  \n",
        "\n",
        "    # here we call the conv2d function we had defined above and pass the input image x, weights wc1 and bias bc1.\n",
        "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 14*14 matrix.\n",
        "    conv1 = maxpool2d(conv1, k=2)\n",
        "\n",
        "    # Convolution Layer\n",
        "    # here we call the conv2d function we had defined above and pass the input image x, weights wc2 and bias bc2.\n",
        "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 7*7 matrix.\n",
        "    conv2 = maxpool2d(conv2, k=2)\n",
        "\n",
        "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
        "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 4*4.\n",
        "    conv3 = maxpool2d(conv3, k=2)\n",
        "\n",
        "\n",
        "    # Fully connected layer\n",
        "    # Reshape conv2 output to fit fully connected layer input\n",
        "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "    # Output, class prediction\n",
        "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
        "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHI1cIjy9WSi",
        "colab_type": "code",
        "outputId": "14acd692-3653-4cc0-da11-55d19906dce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "pred = conv_net(x, weights, biases)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-17-224e58f506fb>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb7-CCKx-atM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init) \n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    train_accuracy = []\n",
        "    test_accuracy = []\n",
        "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
        "    for i in range(training_iters):\n",
        "        for batch in range(len(train_X)//batch_size):\n",
        "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
        "            batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
        "            # Run optimization op (backprop).\n",
        "                # Calculate batch loss and accuracy\n",
        "            opt = sess.run(optimizer, feed_dict={x: batch_x,y: batch_y})\n",
        "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,y: batch_y})\n",
        "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
        "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                      \"{:.5f}\".format(acc))\n",
        "        print(\"Optimization Finished!\")\n",
        "\n",
        "        # Calculate accuracy for all 10000 mnist test images\n",
        "        test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
        "        train_loss.append(loss)\n",
        "        test_loss.append(valid_loss)\n",
        "        train_accuracy.append(acc)\n",
        "        test_accuracy.append(test_acc)\n",
        "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
        "    summary_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnKnXwwl-69q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}